{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SkdYWGMkjwph"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 1))) #the input shape will depend on the downsampling we do to our spectrograms (1 bc greyscale)\n",
        "model.add(layers.MaxPooling2D((2, 2))) #this is kind of a downsampling\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu')) #the 3,3 is the kernel size\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "model.add(layers.Flatten()) #to connect the convolution layers to the dense layers\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(6), activation='softmax') #always softmax for last layer that classifies, bc it will give probabilities of a sample belonging to a class"
      ],
      "metadata": {
        "id": "cMYZrCeDj0d2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "dM59KOpPkFZ8"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}